'use strict';

const Path = require('path');
const Fs = require('fs');
const tf = require('@tensorflow/tfjs-node');
const config = require('../config');
const logger = require('../utils/logger');

// Global variables for loaded models
let landmarkModel = null;
let videoLstmModel = null;
let videoTransformerModel = null;
let imageClassMapping = {};
let videoClassMapping = {};

/**
 * Load all models and class mappings
 * @returns {Promise<Object>} Status of loaded models
 */
async function loadModels() {
  try {
    logger.info('Loading models and class mappings...');
    
    // Ensure model directory exists
    if (!Fs.existsSync(config.models.directory)) {
      logger.warn(`Model directory does not exist, creating: ${config.models.directory}`);
      Fs.mkdirSync(config.models.directory, { recursive: true });
    }
    
    // Load class mappings
    const imageClassMappingPath = Path.join(
      config.models.directory, 
      config.models.files.imageClassMapping
    );
    
    const videoClassMappingPath = Path.join(
      config.models.directory, 
      config.models.files.videoClassMapping
    );
    
    if (Fs.existsSync(imageClassMappingPath)) {
      try {
        imageClassMapping = JSON.parse(Fs.readFileSync(imageClassMappingPath, 'utf8'));
        logger.info(`Image class mapping loaded with ${Object.keys(imageClassMapping).length} classes`);
      } catch (error) {
        logger.error('Error parsing image class mapping:', error);
      }
    } else {
      logger.warn(`Image class mapping file not found at: ${imageClassMappingPath}`);
    }
    
    if (Fs.existsSync(videoClassMappingPath)) {
      try {
        videoClassMapping = JSON.parse(Fs.readFileSync(videoClassMappingPath, 'utf8'));
        logger.info(`Video class mapping loaded with ${Object.keys(videoClassMapping).length} classes`);
      } catch (error) {
        logger.error('Error parsing video class mapping:', error);
      }
    } else {
      logger.warn(`Video class mapping file not found at: ${videoClassMappingPath}`);
    }
    
    // Log full model paths for debugging
    const landmarkModelPath = Path.join(
      config.models.directory, 
      config.models.files.landmarkModel
    );
    
    const videoLstmModelPath = Path.join(
      config.models.directory, 
      config.models.files.videoLstmModel
    );
    
    const videoTransformerModelPath = Path.join(
      config.models.directory, 
      config.models.files.videoTransformerModel
    );
    
    logger.info('Model paths:');
    logger.info(`Landmark model: ${landmarkModelPath}`);
    logger.info(`Video LSTM model: ${videoLstmModelPath}`);
    logger.info(`Video Transformer model: ${videoTransformerModelPath}`);
    
    // Check directories and create if needed
    const landmarkModelDir = Path.dirname(landmarkModelPath);
    const videoLstmModelDir = Path.dirname(videoLstmModelPath);
    const videoTransformerModelDir = Path.dirname(videoTransformerModelPath);
    
    if (!Fs.existsSync(landmarkModelDir)) {
      logger.warn(`Creating landmark model directory: ${landmarkModelDir}`);
      Fs.mkdirSync(landmarkModelDir, { recursive: true });
    }
    
    if (!Fs.existsSync(videoLstmModelDir)) {
      logger.warn(`Creating video LSTM model directory: ${videoLstmModelDir}`);
      Fs.mkdirSync(videoLstmModelDir, { recursive: true });
    }
    
    if (!Fs.existsSync(videoTransformerModelDir)) {
      logger.warn(`Creating video transformer model directory: ${videoTransformerModelDir}`);
      Fs.mkdirSync(videoTransformerModelDir, { recursive: true });
    }
    
    // Mock model loading for testing if model files don't exist
    // Remove this section in production
    if (!Fs.existsSync(landmarkModelPath)) {
      logger.warn(`Landmark model file not found: ${landmarkModelPath}`);
      logger.warn('Using mock model for testing');
      
      // Create simple mock model for testing
      const inputs = tf.input({shape: [config.models.params.numLandmarkFeatures]});
      const outputs = tf.layers.dense({units: 26, activation: 'softmax'}).apply(inputs);
      landmarkModel = tf.model({inputs, outputs});
      landmarkModel.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });
      logger.info('Mock landmark model created successfully');
    } else {
      try {
        logger.info(`Loading landmark model from: ${landmarkModelPath}`);
        landmarkModel = await tf.loadLayersModel(`file://${Path.resolve(landmarkModelPath)}`);
        logger.info('Landmark model loaded successfully');
      } catch (error) {
        logger.error('Error loading landmark model:', error);
      }
    }
    
    if (!Fs.existsSync(videoLstmModelPath)) {
      logger.warn(`Video LSTM model file not found: ${videoLstmModelPath}`);
      logger.warn('Using mock model for testing');
      
      // Create simple mock model for testing
      const inputs = tf.input({shape: [config.models.params.numFramesVideo, config.models.params.numLandmarkFeatures]});
      const lstm = tf.layers.lstm({units: 64, returnSequences: false}).apply(inputs);
      const outputs = tf.layers.dense({units: 10, activation: 'softmax'}).apply(lstm);
      videoLstmModel = tf.model({inputs, outputs});
      videoLstmModel.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });
      logger.info('Mock video LSTM model created successfully');
    } else {
      try {
        logger.info(`Loading video LSTM model from: ${videoLstmModelPath}`);
        videoLstmModel = await tf.loadLayersModel(`file://${Path.resolve(videoLstmModelPath)}`);
        logger.info('Video LSTM model loaded successfully');
      } catch (error) {
        logger.error('Error loading video LSTM model:', error);
      }
    }
    
    if (!Fs.existsSync(videoTransformerModelPath)) {
      logger.warn(`Video transformer model file not found: ${videoTransformerModelPath}`);
      logger.warn('Using mock model for testing');
      
      // Create simple mock model for testing
      const inputs = tf.input({shape: [config.models.params.numFramesVideo, config.models.params.numLandmarkFeatures]});
      const flatten = tf.layers.flatten().apply(inputs);
      const dense = tf.layers.dense({units: 64, activation: 'relu'}).apply(flatten);
      const outputs = tf.layers.dense({units: 10, activation: 'softmax'}).apply(dense);
      videoTransformerModel = tf.model({inputs, outputs});
      videoTransformerModel.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });
      logger.info('Mock video transformer model created successfully');
    } else {
      try {
        logger.info(`Loading video transformer model from: ${videoTransformerModelPath}`);
        videoTransformerModel = await tf.loadLayersModel(`file://${Path.resolve(videoTransformerModelPath)}`);
        logger.info('Video transformer model loaded successfully');
      } catch (error) {
        logger.error('Error loading video transformer model:', error);
      }
    }
    
    // Return model status
    const status = {
      landmarkModel: landmarkModel !== null,
      videoLstmModel: videoLstmModel !== null,
      videoTransformerModel: videoTransformerModel !== null,
      imageClassMapping: Object.keys(imageClassMapping).length > 0,
      videoClassMapping: Object.keys(videoClassMapping).length > 0
    };
    
    logger.info('Model loading completed with status:', status);
    return status;
  } catch (error) {
    logger.error('Error in loadModels function:', error);
    throw error;
  }
}

/**
 * Predict static sign (letter) from landmarks
 * @param {Array} landmarks - Flattened array of hand landmarks
 * @returns {Promise<Object>} Prediction result
 */
async function predictStaticSign(landmarks) {
  if (!landmarkModel) {
    throw new Error('Landmark model not loaded');
  }
  
  // Convert landmarks to tensor
  const tensor = tf.tensor2d([landmarks], [1, config.models.params.numLandmarkFeatures]);
  
  // Predict
  const predictions = await landmarkModel.predict(tensor).data();
  
  // Get the highest prediction
  let maxIndex = 0;
  let maxConfidence = 0;
  
  for (let i = 0; i < predictions.length; i++) {
    if (predictions[i] > maxConfidence) {
      maxConfidence = predictions[i];
      maxIndex = i;
    }
  }
  
  // Get the class name
  const predictedClass = imageClassMapping[maxIndex] || 'Unknown';
  
  // Clean up
  tensor.dispose();
  
  return {
    class: predictedClass,
    confidence: maxConfidence,
    index: maxIndex
  };
}

/**
 * Predict dynamic sign (word) from landmark sequence
 * @param {Array} landmarkSequence - Array of landmark arrays
 * @param {string} modelChoice - 'lstm' or 'transformer'
 * @returns {Promise<Object>} Prediction result
 */
async function predictDynamicSign(landmarkSequence, modelChoice = 'transformer') {
  // Choose model based on modelChoice
  const model = modelChoice === 'transformer' ? videoTransformerModel : videoLstmModel;
  
  if (!model) {
    throw new Error(`${modelChoice} model not loaded`);
  }
  
  // Ensure sequence has correct dimensions
  let processedSequence = landmarkSequence;
  const numFrames = config.models.params.numFramesVideo;
  const numFeatures = config.models.params.numLandmarkFeatures;
  
  // Pad or truncate sequence to correct length
  if (landmarkSequence.length < numFrames) {
    // Pad with zeros
    processedSequence = [
      ...landmarkSequence,
      ...Array(numFrames - landmarkSequence.length).fill(Array(numFeatures).fill(0))
    ];
  } else if (landmarkSequence.length > numFrames) {
    // Truncate
    processedSequence = landmarkSequence.slice(0, numFrames);
  }
  
  // Convert to tensor
  const tensor = tf.tensor3d([processedSequence], [1, numFrames, numFeatures]);
  
  // Predict
  const predictions = await model.predict(tensor).data();
  
  // Get the highest prediction
  let maxIndex = 0;
  let maxConfidence = 0;
  
  for (let i = 0; i < predictions.length; i++) {
    if (predictions[i] > maxConfidence) {
      maxConfidence = predictions[i];
      maxIndex = i;
    }
  }
  
  // Get the class name
  const predictedClass = videoClassMapping[maxIndex] || 'Unknown';
  
  // Clean up
  tensor.dispose();
  
  return {
    class: predictedClass,
    confidence: maxConfidence,
    index: maxIndex,
    modelUsed: modelChoice
  };
}

/**
 * Convert text to sign language
 * @param {string} text - Input text
 * @returns {Object} Sign language representation
 */
function textToSign(text) {
  if (!text) {
    throw new Error('No text provided');
  }
  
  // Parse text and convert to signs
  const words = text.trim().toLowerCase().split(/\s+/);
  const result = [];
  
  for (const word of words) {
    // Check if word exists in video class mapping (known words)
    let isKnownWord = false;
    let mappedWord = word;
    
    for (const [key, value] of Object.entries(videoClassMapping)) {
      if (value.toLowerCase() === word) {
        isKnownWord = true;
        mappedWord = value; // Use the exact case from the mapping
        break;
      }
    }
    
    if (isKnownWord) {
      // Known word - can be represented as a single sign
      result.push({
        type: 'word',
        original: word,
        mapped: mappedWord,
        knownInDataset: true
      });
    } else {
      // Unknown word - needs to be fingerspelled
      const letters = [];
      
      for (const letter of word) {
        // Check if we have this letter in our image classes
        let letterExists = false;
        let mappedLetter = letter.toUpperCase();
        
        // Look through the image class mapping for this letter
        for (const [key, value] of Object.entries(imageClassMapping)) {
          if (value.toLowerCase() === letter.toLowerCase()) {
            letterExists = true;
            mappedLetter = value; // Use the exact case from the mapping
            break;
          }
        }
        
        letters.push({
          letter: letter,
          mapped: mappedLetter,
          exists: letterExists
        });
      }
      
      result.push({
        type: 'fingerspell',
        original: word,
        letters: letters
      });
    }
  }
  
  return {
    text: text,
    signs: result
  };
}

/**
 * Get available words from the vocabulary
 * @returns {Array} List of available words
 */
function getAvailableWords() {
  return Object.entries(videoClassMapping).map(([key, value]) => ({
    id: key,
    word: value
  }));
}

/**
 * Get available letters from the vocabulary
 * @returns {Array} List of available letters
 */
function getAvailableLetters() {
  return Object.entries(imageClassMapping).map(([key, value]) => ({
    id: key,
    letter: value
  }));
}

/**
 * Get model status
 * @returns {Object} Status of loaded models
 */
function getModelStatus() {
  return {
    landmarkModel: landmarkModel !== null,
    videoLstmModel: videoLstmModel !== null,
    videoTransformerModel: videoTransformerModel !== null,
    imageClassMapping: Object.keys(imageClassMapping).length > 0,
    videoClassMapping: Object.keys(videoClassMapping).length > 0
  };
}

module.exports = {
  loadModels,
  predictStaticSign,
  predictDynamicSign,
  textToSign,
  getAvailableWords,
  getAvailableLetters,
  getModelStatus
};